{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fe4db912",
   "metadata": {},
   "source": [
    "## Configure a face library system"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fac6a6e",
   "metadata": {},
   "source": [
    " Structure of our library system:\n",
    "\n",
    "```library```<br/>\n",
    "|__```celebrity_1``` <br/>\n",
    "|   |   meta.npz\n",
    "|    |   face_1.png\n",
    "|    |   face_2.png\n",
    "|    \n",
    "|__```celeberity_2```\n",
    "|\n",
    "|\n",
    "|\n",
    "|___```(videoname)_(cluster no.)```\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2c690694",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants here\n",
    "LIB_ROOT = '/home/ubuntu/visual_search_assistant/M3/library'\n",
    "META_FNAME = 'meta.npz'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "343371ba",
   "metadata": {},
   "source": [
    "### Pre-processing the library\n",
    "Extract encoding from faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "120fd9b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import face_recognition\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "def extract_encodings_dir(dir,mean=False):\n",
    "    images = []\n",
    "    names = []\n",
    "    encodings = []\n",
    "    \n",
    "    for image_pth in os.listdir(dir):\n",
    "        if image_pth.endswith('npz'):\n",
    "            continue\n",
    "        img = face_recognition.load_image_file(os.path.join(dir,image_pth))\n",
    "        images.append(img)\n",
    "        names.append(image_pth)\n",
    "    \n",
    "    for idx,(img,name) in enumerate(zip(images,names)):\n",
    "        print('[%d / %d] Extracting encoding for %s' % (idx+1,len(images),name))\n",
    "        embd = face_recognition.face_encodings(img)[0]\n",
    "        encodings.append(embd)\n",
    "    \n",
    "    if mean:\n",
    "        res = np.mean(encodings,axis=0)\n",
    "        return res\n",
    "    else:\n",
    "        return encodings\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81a9cd80",
   "metadata": {},
   "source": [
    "### Pre-process the library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bac3fd8f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 / 1] Extracting encoding for goora_kim.jpg\n",
      "Processing identity goora_kim\n",
      "[1 / 1] Extracting encoding for youngmi_ahn.jpeg\n",
      "Processing identity youngmi_ahn\n",
      "[1 / 1] Extracting encoding for radio_star.jpg\n",
      "Processing identity radio_star\n",
      "[1 / 1] Extracting encoding for Donna_Meagle.jpg\n",
      "Processing identity Donna_Meagle\n",
      "[1 / 1] Extracting encoding for leslie_knope.jpg\n",
      "Processing identity leslie_knope\n",
      "[1 / 1] Extracting encoding for gookjin_kim.jpeg\n",
      "Processing identity gookjin_kim\n",
      "--Return--\n",
      "None\n",
      "> \u001b[0;32m/tmp/ipykernel_24449/1582884184.py\u001b[0m(33)\u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     31 \u001b[0;31m    \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Processing identity %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     32 \u001b[0;31m\u001b[0;31m#     import pdb;pdb.set_trace()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m---> 33 \u001b[0;31m\u001b[0;32mimport\u001b[0m \u001b[0mpdb\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0mpdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     34 \u001b[0;31m\u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetadata_pth\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     35 \u001b[0;31m    \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mHIGHEST_PROTOCOL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> metadata.keys()\n",
      "dict_keys(['goora_kim', 'youngmi_ahn', 'radio_star', 'Donna_Meagle', 'leslie_knope', 'gookjin_kim'])\n",
      "ipdb> c\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "\n",
    "# preprocessing : convert single files into directories\n",
    "identities = os.listdir(LIB_ROOT)\n",
    "metadata_pth = os.path.join(LIB_ROOT,'meta.npz')\n",
    "metadata = {\n",
    "}\n",
    "for fname in identities:\n",
    "    src_pth = os.path.join(LIB_ROOT,fname)\n",
    "    \n",
    "    if not os.path.isdir(src_pth):\n",
    "        \n",
    "        name = src_pth.split('.')[0]\n",
    "        dst_pth = os.path.join(LIB_ROOT,name)\n",
    "        os.mkdir(dst_pth) # create directory for the identity\n",
    "        os.rename(src_pth,os.path.join(dst_pth,fname)) # move single image file\n",
    "        src_pth = dst_pth\n",
    "        print(\"Created new directory for %s\" % name)\n",
    "    else:\n",
    "        name = fname\n",
    "        \n",
    "    mean_encoding = extract_encodings_dir(src_pth,mean=True)\n",
    "    metadata[fname] = {\n",
    "        \"encoding\":mean_encoding,\n",
    "        \"name\":'',\n",
    "        \"id\":fname,\n",
    "        \"clusterlist\":[fname]\n",
    "    }\n",
    "    \n",
    "    print(\"Processing identity %s\" % name)\n",
    "with open(metadata_pth,'wb') as f:\n",
    "    pickle.dump(metadata,f,protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffcc36ef",
   "metadata": {},
   "source": [
    "Check if correctly saved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ec00ec3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['goora_kim', 'youngmi_ahn', 'radio_star', 'Donna_Meagle', 'leslie_knope', 'gookjin_kim'])\n",
      "dict_keys(['encoding', 'name', 'id', 'clusterlist'])\n"
     ]
    }
   ],
   "source": [
    "example_meta_pth = '/home/ubuntu/visual_search_assistant/M3/library//meta.npz'\n",
    "import pickle\n",
    "\n",
    "with open(example_meta_pth,'rb') as rf:\n",
    "    metadata = pickle.load(rf)\n",
    "\n",
    "print(metadata.keys())\n",
    "print(metadata['goora_kim'].keys())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_vsa)",
   "language": "python",
   "name": "conda_vsa"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
