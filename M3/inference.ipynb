{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "874b3336",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic constants\n",
    "\n",
    "OUTPUT_DIR = '/home/ubuntu/visual_search_assistant/M3/results'\n",
    "FACE_LIB_DIR = '/home/ubuntu/visual_search_assistant/M3/library/'\n",
    "DATA_DIR = '/home/ubuntu/visual_search_assistant/data'\n",
    "SAMPLE_FRAME_FREQ = 2\n",
    "SAMPLE_CLUSTER_FREQ = 20\n",
    "LOG_FREQ = 50\n",
    "\n",
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8de19a44-7664-48a2-b1e8-86b6280346ba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!export OPENBLAS_CORETYPE=ARMV8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd861086",
   "metadata": {},
   "source": [
    "## Library of face embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1af0869",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# import face_recognition\n",
    "import pickle\n",
    "\n",
    "meta_pth = '/dli/task/visual_search_assistant/M3/library/meta.npz' #'/home/ubuntu/visual_search_assistant/M3/library/meta.npz'\n",
    "all_embeddings = []\n",
    "all_names = []\n",
    "with open(meta_pth,'rb') as f:\n",
    "    metadata = pickle.load(f)\n",
    "    \n",
    "    for idx,(key,val) in enumerate(metadata.items()):\n",
    "        all_embeddings.append(val['encoding'])\n",
    "        all_names.append(key)\n",
    "\n",
    "print(\"✔️ List of all_names: \\n\",all_names)\n",
    "print(\"✔️ Shape of single face encoding: \\n\", all_embeddings[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87bc881d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def process_video(input_pth,output_pth=None,use_gpu=True,recognition=False,detection_threshold=0.7,\n",
    "                  result_dir=None,max_frames=None,sample_cluster_freq=2,sample_freq=2,batch_size=1):\n",
    "    if output_pth is None:\n",
    "        output_pth = os.path.join(OUTPUT_DIR,input_pth.split('/')[-1])\n",
    "    if use_gpu:\n",
    "        batch_size = 16\n",
    "    \n",
    "    if result_dir is None:\n",
    "        import pdb;pdb.set_trace()\n",
    "        input_name = input_pth.split('/')[-1].split('.')[0]\n",
    "        \n",
    "        result_dir = os.path.join(OUTPUT_DIR,input_name)\n",
    "    \n",
    "    if not os.path.exists(result_dir):\n",
    "        sampled_face_dir = os.path.join(result_dir,'sampled_faces')\n",
    "        os.makedirs(sampled_face_dir)\n",
    "    else:\n",
    "        print('Error result dir %s already exists! aborting' % result_dir)\n",
    "        sampled_face_dir = os.path.join(result_dir,'sampled_faces')\n",
    "#         return\n",
    "    \n",
    "    \n",
    "    cluster_dict = {}\n",
    "    \n",
    "    video_capture = cv2.VideoCapture(input_pth)\n",
    "\n",
    "    frame_width = int(video_capture.get(3))\n",
    "    frame_height = int(video_capture.get(4))\n",
    "    \n",
    "    fps = video_capture.get(cv2. CAP_PROP_FPS)\n",
    "    nframes = int(video_capture.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    length = nframes/fps\n",
    "    \n",
    "    fourcc = cv2.VideoWriter_fourcc('m', 'p', '4', 'v')\n",
    "    out = cv2.VideoWriter(output_pth, fourcc, 30.0, (frame_width, frame_height))\n",
    "    \n",
    "    frame_count = 0\n",
    "    \n",
    "    frames = []\n",
    "    print('='*20,'Start Face Detection and Recognition','='*20)\n",
    "    while video_capture.isOpened():\n",
    "        ret, frame = video_capture.read()\n",
    "        \n",
    "        if not ret or (max_frames and frame_count > max_frames):\n",
    "            break\n",
    "        if frame_count % LOG_FREQ == LOG_FREQ -1:\n",
    "            print('Processed %d frames'% frame_count)\n",
    "            \n",
    "        frame_count += 1\n",
    "        \n",
    "        # skip frames\n",
    "        if frame_count % sample_freq > 0:\n",
    "            continue\n",
    "            \n",
    "        frames.append(frame)\n",
    "        if len(frames) == batch_size:\n",
    "#             import pdb;pdb.set_trace()\n",
    "            batch_face_locations = face_recognition.batch_face_locations(frames)\n",
    "            for frame_idx,face_locations in enumerate(batch_face_locations):\n",
    "                print('reaches here')\n",
    "                number_of_faces_in_frame = len(face_locations)\n",
    "                \n",
    "                fno = frame_count - batch_size + frame_idx\n",
    "                frame = frames[frame_idx]\n",
    "                \n",
    "                \n",
    "                embeddings = face_recognition.face_encodings(frame,face_locations)\n",
    "                for face_idx,(embd,(top,right,bottom,left)) in enumerate(zip(embeddings,face_locations)):\n",
    "                    # Draw a box around the face\n",
    "                    cv2.rectangle(frame, (left, top), (right, bottom), (0, 0, 255), 2)\n",
    "                    # Draw a label with a name below the face\n",
    "                    cv2.rectangle(frame, (left, bottom + 35), (right, bottom), (0, 0, 255), cv2.FILLED)\n",
    "                    \n",
    "                    \n",
    "                    # write label\n",
    "                    face_dist = face_recognition.face_distance(all_embeddings,embd)\n",
    "                    label_idx = np.argmin(face_dist)\n",
    "                    name = all_names[label_idx] if face_dist[label_idx] > detection_threshold else 'Unknown'\n",
    "                    font = cv2.FONT_HERSHEY_DUPLEX\n",
    "                    cv2.putText(frame, name, (left + 6, bottom + 6), font, 0.5, (255, 255, 255), 1)\n",
    "                    \n",
    "                    \n",
    "                    # save face image for clustering\n",
    "                    if frame_idx % sample_cluster_freq ==0:\n",
    "                        fname = '%.3d_%.3d.png'%(fno,face_idx)\n",
    "                        face_img = frame[top:bottom,left:right,:]\n",
    "                        # save face image\n",
    "                        cv2.imwrite(os.path.join(sampled_face_dir,fname),face_img)\n",
    "                        # save embd in dict\n",
    "                        cluster_dict[fname.split('.')[0]] = embd\n",
    "                                \n",
    "                out.write(frame)\n",
    "            frames = []\n",
    "                \n",
    "                \n",
    "    video_capture.release()\n",
    "    out.release()\n",
    "    \n",
    "    # save sampled embeddings as pickle file\n",
    "#     import pdb;pdb.set_trace()\n",
    "    cluster_meta_file = os.path.join(result_dir,'embeddings.pickle')\n",
    "    with open(cluster_meta_file,'wb') as f:\n",
    "        pickle.dump(cluster_dict,f,protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "    print('='*15,'Done Processing %s to %s' % (input_pth,output_pth),'='*15)\n",
    "    \n",
    "    return name,nframes,length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82fec96b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_input_video = '/dli/task/visual_search_assistant/M3/data/parks_and_rec_0_10.mp4' #'/home/ubuntu/visual_search_assistant/data/radio_star_10_20.mp4'\n",
    "vid_name,vid_nframes,vid_length = process_video(test_input_video,max_frames=64,batch_size=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db36abb1",
   "metadata": {},
   "source": [
    "### Check sampled faces & embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "678489c2",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'matplotlib'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-d59b98517233>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmpimg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'matplotlib'"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "import glob\n",
    "\n",
    "def display_multiple_images(images,names,columns=10,figsize=(20,10)):\n",
    "    plt.figure(figsize=figsize)\n",
    "    plt.subplots_adjust(wspace=0, hspace=0)\n",
    "    for i, (image,name) in enumerate(zip(images,names)):\n",
    "        plt.subplot(int(len(images) / columns + 1), columns, i + 1)\n",
    "        plt.imshow(image)\n",
    "        plt.axis('off')\n",
    "        plt.title(name) \n",
    "        \n",
    "\n",
    "num_images = 30\n",
    "%matplotlib inline\n",
    "\n",
    "print('='*10,'Display sampled faces','='*10)\n",
    "print(\"title is in <(frame number)_(detected face id)> format\")\n",
    "\n",
    "images = []\n",
    "names = []\n",
    "for img_path in glob.glob(os.path.join(result_dir,'sampled_faces','*.png')):\n",
    "    images.append(mpimg.imread(img_path))\n",
    "    names.append(img_path.split('/')[-1].split('.')[0])\n",
    "    if len(images) == num_images:\n",
    "        break\n",
    "        \n",
    "        \n",
    "display_multiple_images(images,names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a73f908",
   "metadata": {},
   "outputs": [],
   "source": [
    "embd_pkl_file = '/home/ubuntu/visual_search_assistant/M3/results/radio_star_10_20/embeddings.pickle'\n",
    "result_dir = '/home/ubuntu/visual_search_assistant/M3/results/radio_star_10_20'\n",
    "\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "with open(embd_pkl_file,'rb') as rf:\n",
    "    embedding_dict = pickle.load(rf)\n",
    "\n",
    "embedding_dict.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f097960",
   "metadata": {},
   "source": [
    "## Cluster Some Faces!\n",
    "Use a clustering algorithm from Scikit\n",
    "https://pyimagesearch.com/2018/07/09/face-clustering-with-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "78def5e9",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-a172b6688662>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0membeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membedding_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mnames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membedding_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "embeddings = np.array(list(embedding_dict.values()))\n",
    "names = np.array(list(embedding_dict.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f4bd462c",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-e629ee82ae53>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcluster\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDBSCAN\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mclt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDBSCAN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetric\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"euclidean\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mclt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'sklearn'"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import DBSCAN\n",
    "\n",
    "clt = DBSCAN(metric=\"euclidean\", n_jobs=-1)\n",
    "clt.fit(embeddings)\n",
    "\n",
    "# determine the total number of unique faces found in the dataset\n",
    "labelIDs = np.unique(clt.labels_)\n",
    "numUniqueFaces = len(np.where(labelIDs > -1)[0])\n",
    "print(\"[INFO] # unique faces: {}\".format(numUniqueFaces))\n",
    "\n",
    "print(\"Save clustered results in dict\")\n",
    "cluster = {}\n",
    "# save separately as clusters\n",
    "for cluster_idx in labelIDs:\n",
    "    idxs = np.where(clt.labels_ == cluster_idx)\n",
    "    cluster[cluster_idx] = names[idxs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "531cb82b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "# helper function for converting fnames to images for using imutils build_montages function\n",
    "def fnames2images(fnames,dir=None):\n",
    "    faces = []\n",
    "    for fname in fnames:\n",
    "        if not fname.endswith('.png'):\n",
    "            fname = fname + '.png'\n",
    "        image = cv2.imread(os.path.join(dir,fname))\n",
    "        face = cv2.resize(image, (96,96))\n",
    "        faces.append(face)\n",
    "    return faces"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2632487",
   "metadata": {},
   "source": [
    "#### Visualize the cluster results!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b97a732",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imutils import build_montages\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.subplots_adjust(wspace=0, hspace=0)\n",
    "\n",
    "for idx,(key,name_list) in enumerate(cluster.items()):\n",
    "    faces = fnames2images(name_list,dir=os.path.join(result_dir,'sampled_faces'))\n",
    "    montage = build_montages(faces,(96,96),(5,5))[0]\n",
    "    title = \"Faces for cluster %d\" % key if key!=-1 else \"Unknown Faces\"\n",
    "    plt.subplot(1,3,idx+1)\n",
    "    plt.axis('off')\n",
    "    plt.title(title)\n",
    "    plt.imshow(cv2.cvtColor(montage,cv2.COLOR_BGR2RGB))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ada4687",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40fe5a1f",
   "metadata": {},
   "source": [
    "### Write Results to Opensearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed611c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from search import *\n",
    "\n",
    "print(\"=\"*10, \"Check client status\")\n",
    "print(client.info())\n",
    "\n",
    "INDEX_CLUSTERS = \"clusters\"\n",
    "INDEX_VIDEOS = \"videos\"\n",
    "\n",
    "# vid_name will be the id\n",
    "vid_document = {\n",
    "    'id': vid_name,\n",
    "    'nframes': vid_nframes,\n",
    "    'length': vid_length,\n",
    "}\n",
    "# cluster name will be id\n",
    "cluster_document = {\n",
    "    'id': 'test_0',\n",
    "    'center': embeddings[0],\n",
    "    'num_faces': 40,\n",
    "    'list_frames':['000_001','000_003']\n",
    "}\n",
    "\n",
    "print(\"Send results for the new video\")\n",
    "create_or_update(INDEX_VIDEOS,vid_name,vid_document)\n",
    "\n",
    "print(\"Send results for each cluster\")\n",
    "create_or_update(INDEX_CLUSTERS,'test_0',cluster_document)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd203907",
   "metadata": {},
   "source": [
    "Deleting an index (shouldn't need this...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f95b74c8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# client.indices.delete(index=\"videos\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
