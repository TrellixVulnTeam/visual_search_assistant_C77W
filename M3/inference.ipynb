{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "874b3336",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic constants\n",
    "\n",
    "OUTPUT_DIR = '/home/ubuntu/visual_search_assistant/M3/results'\n",
    "FACE_LIB_DIR = '/home/ubuntu/visual_search_assistant/M3/library/'\n",
    "DATA_DIR = '/home/ubuntu/visual_search_assistant/data'\n",
    "SAMPLE_FRAME_FREQ = 2\n",
    "SAMPLE_CLUSTER_FREQ = 20\n",
    "LOG_FREQ = 50\n",
    "\n",
    "batch_size = 128\n",
    "\n",
    "input_video = None\n",
    "output_video = None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6804643c",
   "metadata": {},
   "source": [
    "## Download Test Videos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26cf5a51",
   "metadata": {},
   "source": [
    "Functions to download youtube video from link and clip them "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "2964fc31",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytube import YouTube \n",
    "from moviepy.editor import *\n",
    "\n",
    "def download_video(link,output_path,output_title=None):\n",
    "    yt = YouTube(link)\n",
    "    video_stream = yt.streams.first()\n",
    "    video_stream.download(output_path=output_path,filename=output_title)\n",
    "    print('Download complete for %s' % video_stream.title)\n",
    "    return video_stream.title\n",
    "\n",
    "\n",
    "def clip_video(video_pth,output_pth,time):\n",
    "    \"\"\"\n",
    "    video_pth: /path/to/input/video\n",
    "    output_pth: /path/to/output/video\n",
    "    time: list of start and end time in seconds to clip video\n",
    "    \"\"\"\n",
    "\n",
    "    start,end=time\n",
    "    clip = VideoFileClip(video_pth).subclip(start,end)\n",
    "    if output_pth is None:\n",
    "        name = video_pth.split('/')[-1].split('.')[0]\n",
    "        new_name = name + '_%d_%d'%(start,end)\n",
    "        output_pth = video_pth.replace(name,new_name)\n",
    "        \n",
    "    #import pdb; pdb.set_trace()\n",
    "    clip.write_videofile(output_pth)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c31bb137",
   "metadata": {},
   "source": [
    "Specify the link and download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "683f7e3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download complete for Donna Wakes Up Everyday And Chooses Being Cool | Parks and Recreation\n"
     ]
    }
   ],
   "source": [
    "download_link = 'https://www.youtube.com/watch?v=oHddkxW5IqU'\n",
    "download_link = 'https://www.youtube.com/watch?v=X4uo7uKR61M'\n",
    "fname = 'radio_star_.mp4'\n",
    "fname = 'parks_and_rec_.mp4'\n",
    "\n",
    "output_pth = os.path.join(DATA_DIR,fname)\n",
    "if not os.path.exists(output_pth):\n",
    "    download_video(download_link,DATA_DIR,fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "e21315f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<video src=\"/home/ubuntu/visual_search_assistant/data/Donna Wakes Up Everyday And Chooses Being Cool  Parks and Recreation.mp4\" controls>\n",
       "      Your browser does not support the <code>video</code> element.\n",
       "    </video>"
      ],
      "text/plain": [
       "<IPython.core.display.Video object>"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.core.display import Video\n",
    "Video('/home/ubuntu/visual_search_assistant/data/Donna Wakes Up Everyday And Chooses Being Cool  Parks and Recreation.mp4')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd861086",
   "metadata": {},
   "source": [
    "## Library of face embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f1af0869",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import face_recognition\n",
    "\n",
    "faces = os.listdir(FACE_LIB_DIR)\n",
    "all_embeddings = []\n",
    "all_names = []\n",
    "for file in faces:\n",
    "    face = face_recognition.load_image_file(os.path.join(FACE_LIB_DIR,file))\n",
    "    all_embeddings.append(face_recognition.face_encodings(face)[0])\n",
    "    name = file.split('/')[-1].split('.')[0]\n",
    "    all_names.append(name)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "87bc881d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def process_video(input_pth,output_pth=None,use_gpu=True,recognition=False,detection_threshold=0.7,\n",
    "                  result_dir=None,max_frames=None,sample_cluster_freq=2,sample_freq=2,batch_size=1):\n",
    "    if output_pth is None:\n",
    "        output_pth = os.path.join(OUTPUT_DIR,input_pth.split('/')[-1])\n",
    "    if use_gpu:\n",
    "        batch_size = 16\n",
    "    \n",
    "    if result_dir is None:\n",
    "        import pdb;pdb.set_trace()\n",
    "        input_name = input_pth.split('/')[-1].split('.')[0]\n",
    "        result_dir = os.path.join(OUTPUT_DIR,input_name)\n",
    "    \n",
    "    if not os.path.exists(result_dir):\n",
    "        sampled_face_dir = os.path.join(result_dir,'sampled_faces')\n",
    "        os.makedirs(sampled_face_dir)\n",
    "    else:\n",
    "        print('Error result dir %s already exists! aborting' % result_dir)\n",
    "        sampled_face_dir = os.path.join(result_dir,'sampled_faces')\n",
    "#         return\n",
    "    \n",
    "    \n",
    "    cluster_dict = {}\n",
    "    \n",
    "    video_capture = cv2.VideoCapture(input_pth)\n",
    "\n",
    "    frame_width = int(video_capture.get(3))\n",
    "    frame_height = int(video_capture.get(4))\n",
    "    \n",
    "    fourcc = cv2.VideoWriter_fourcc('m', 'p', '4', 'v')\n",
    "    out = cv2.VideoWriter(output_pth, fourcc, 30.0, (frame_width, frame_height))\n",
    "    \n",
    "    frame_count = 0\n",
    "    \n",
    "    frames = []\n",
    "    print('='*20,'Start Face Detection and Recognition','='*20)\n",
    "    while video_capture.isOpened():\n",
    "        ret, frame = video_capture.read()\n",
    "        \n",
    "        if not ret or (max_frames and frame_count > max_frames):\n",
    "            break\n",
    "        if frame_count % LOG_FREQ == LOG_FREQ -1:\n",
    "            print('Processed %d frames'% frame_count)\n",
    "            \n",
    "        frame_count += 1\n",
    "        \n",
    "        # skip frames\n",
    "        if frame_count % sample_freq > 0:\n",
    "            continue\n",
    "            \n",
    "        frames.append(frame)\n",
    "        if len(frames) == batch_size:\n",
    "#             import pdb;pdb.set_trace()\n",
    "            batch_face_locations = face_recognition.batch_face_locations(frames)\n",
    "            for idx,face_locations in enumerate(batch_face_locations):\n",
    "                number_of_faces_in_frame = len(face_locations)\n",
    "                \n",
    "                fno = frame_count - batch_size + idx\n",
    "                frame = frames[idx]\n",
    "                \n",
    "                \n",
    "                embeddings = face_recognition.face_encodings(frame,face_locations)\n",
    "                for iidx,(embd,(top,right,bottom,left)) in enumerate(zip(embeddings,face_locations)):\n",
    "                    # Draw a box around the face\n",
    "                    cv2.rectangle(frame, (left, top), (right, bottom), (0, 0, 255), 2)\n",
    "                    # Draw a label with a name below the face\n",
    "                    cv2.rectangle(frame, (left, bottom + 35), (right, bottom), (0, 0, 255), cv2.FILLED)\n",
    "                    \n",
    "                    \n",
    "                    # write label\n",
    "                    face_dist = face_recognition.face_distance(all_embeddings,embd)\n",
    "                    i = np.argmin(face_dist)\n",
    "                    name = all_names[i] if face_dist[i] > detection_threshold else 'Unknown'\n",
    "                    font = cv2.FONT_HERSHEY_DUPLEX\n",
    "                    cv2.putText(frame, name, (left + 6, bottom + 6), font, 0.5, (255, 255, 255), 1)\n",
    "                    \n",
    "                    \n",
    "                    # save face image for clustering\n",
    "                    if idx % sample_cluster_freq ==0:\n",
    "                        fname = '%.3d_%.3d.png'%(fno,iidx)\n",
    "                        face_img = frame[top:bottom,left:right,:]\n",
    "                        # save face image\n",
    "                        cv2.imwrite(os.path.join(sampled_face_dir,fname),face_img)\n",
    "                        # save embd in dict\n",
    "                        cluster_dict[fname.split('.')[0]] = embd\n",
    "                                \n",
    "                out.write(frame)\n",
    "            frames = []\n",
    "                \n",
    "                \n",
    "    video_capture.release()\n",
    "    out.release()\n",
    "    \n",
    "    # save sampled embeddings as pickle file\n",
    "    import pdb;pdb.set_trace()\n",
    "    cluster_meta_file = os.path.join(result_dir,'embeddings.pickle')\n",
    "    with open(cluster_meta_file,'wb') as f:\n",
    "        pickle.dump(cluster_dict,f,protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "    print('='*15,'Done Processing %s to %s' % (input_pth,output_pth),'='*15)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "82fec96b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> <ipython-input-39-aa42399c9849>(16)process_video()\n",
      "-> input_name = input_pth.split('/')[-1].split('.')[0]\n",
      "(Pdb) c\n",
      "Error result dir /home/ubuntu/visual_search_assistant/M3/results/radio_star_10_20 already exists! aborting\n",
      "==================== Start Face Detection and Recognition ====================\n",
      "Processed 49 frames\n",
      "> <ipython-input-39-aa42399c9849>(101)process_video()\n",
      "-> cluster_meta_file = os.path.join(result_dir,'embeddings.pickle')\n",
      "(Pdb) cluster_dict.keys()\n",
      "dict_keys(['016_000', '016_001', '018_000', '018_001', '020_000', '020_001', '022_000', '022_001', '024_000', '024_001', '026_000', '026_001', '028_000', '028_001', '030_000', '030_001', '048_000', '048_001', '048_002', '050_000', '050_001', '052_000', '052_001', '054_000', '054_001', '056_000', '056_001', '058_000', '060_000', '062_000', '062_001'])\n",
      "(Pdb) c\n",
      "=============== Done Processing /home/ubuntu/visual_search_assistant/data/radio_star_10_20.mp4 to /home/ubuntu/visual_search_assistant/M3/results/radio_star_10_20.mp4 ===============\n"
     ]
    }
   ],
   "source": [
    "test_input_video = '/home/ubuntu/visual_search_assistant/data/radio_star_10_20.mp4'\n",
    "process_video(test_input_video,max_frames=64,batch_size=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db36abb1",
   "metadata": {},
   "source": [
    "### Check sampled faces & embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "1a73f908",
   "metadata": {},
   "outputs": [],
   "source": [
    "embd_pkl_file = '/home/ubuntu/visual_search_assistant/M3/results/radio_star_10_20/embeddings.pickle'\n",
    "\n",
    "with open(embd_pkl_file,'rb') as rf:\n",
    "    embedding_dict = pickle.load(rf)\n",
    "\n",
    "embeddings = np.array(list((embedding_dict.values())))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f097960",
   "metadata": {},
   "source": [
    "## Cluster Some Faces!\n",
    "Use a clustering algorithm from Scikit\n",
    "https://pyimagesearch.com/2018/07/09/face-clustering-with-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "f4bd462c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DBSCAN(n_jobs=-1)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.cluster import DBSCAN\n",
    "\n",
    "clt = DBSCAN(metric=\"euclidean\", n_jobs=-1)\n",
    "clt.fit(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "152ebe8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] # unique faces: 2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-1,  1, -1, -1,  0,  1,  0,  1,  0,  1,  0,  1,  0,  1,  0,  1,  0,\n",
       "        1,  1,  0,  1,  0,  1,  0,  1,  0,  1,  0,  0,  0,  1])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# determine the total number of unique faces found in the dataset\n",
    "labelIDs = np.unique(clt.labels_)\n",
    "numUniqueFaces = len(np.where(labelIDs > -1)[0])\n",
    "print(\"[INFO] # unique faces: {}\".format(numUniqueFaces))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_vsa)",
   "language": "python",
   "name": "conda_vsa"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
